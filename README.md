# ğŸš€ Face Recognition System
### ArcFace + ONNX + 5-Point Alignment (Real-Time, CPU Only)

A clean and practical **real-time face recognition pipeline** that detects, aligns, embeds, and recognizes faces without requiring a GPU.

Built for:
- learning how face recognition works internally
- research and academic projects
- embedded or low-resource systems
- production-style experimentation

---

## âœ¨ Features

- Real-time face detection
- 5-point facial landmark alignment (112Ã—112 crops)
- ArcFace 512â€‘D embeddings
- Cosine similarity matching
- Multi-person enrollment
- Persistent face tracking
- Threshold auto-evaluation
- CPU-only inference
- Modular and easy-to-extend design

---

## ğŸ§  Pipeline Overview

```
Camera
   â†“
Face Detection
   â†“
Landmarks (5 points)
   â†“
Alignment (112x112)
   â†“
ArcFace Embedding (512D)
   â†“
Cosine Similarity
   â†“
Recognized / Unknown
```

Simple idea:
> Image â†’ Align â†’ Convert to numbers â†’ Compare â†’ Decide identity

---

## ğŸ“ Project Structure

```
FaceRecognition/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ camera.py
â”‚   â”œâ”€â”€ detect.py
â”‚   â”œâ”€â”€ landmarks.py
â”‚   â”œâ”€â”€ align.py
â”‚   â”œâ”€â”€ embed.py
â”‚   â”œâ”€â”€ enroll.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ recognise.py
â”œâ”€â”€ data/
â”œâ”€â”€ models/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

### 1. Clone

```bash
git clone <your-repo-url>
cd FaceRecognition
```

### 2. Create virtual environment

Linux / macOS
```bash
python3 -m venv .venv
source .venv/bin/activate
```

Windows
```bash
python -m venv .venv
.venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“¦ Required Models

### ArcFace ONNX model

Place your ArcFace ONNX file here:

```
models/embedder_arcface.onnx
```

Expected:
- Input: 112Ã—112
- Output: 512â€‘dim embedding

---

### MediaPipe landmarker

Place:

```
face_landmarker.task
```

in the project root.

---

## â–¶ï¸ Quick Start

Test step-by-step:

```bash
python -m src.camera
python -m src.detect
python -m src.align
python -m src.embed
```

Enroll people:

```bash
python -m src.enroll
```

Find best threshold:

```bash
python -m src.evaluate
```

Run live recognition:

```bash
python -m src.recognise
```

---

## ğŸ® Controls (Live Mode)

| Key | Action |
|-----|---------|
| q | quit |
| r | reload database |
| + / - | adjust threshold |
| d | debug overlay |
| t | toggle tracking |

---

## ğŸ¯ Enrollment Tips

For best accuracy:

- capture 15â€“20 samples per person
- vary pose and expression
- use good lighting
- keep faces centered
- avoid blur

---

## ğŸ“ Threshold Concept

Embeddings are compared using cosine distance.

- lower distance â†’ same person
- higher distance â†’ different person

Always run `evaluate.py` to automatically compute the best threshold for your data.

Typical range: **0.30 â€“ 0.40**

---

## ğŸ’¡ Why Embeddings Instead of Images?

- smaller storage
- faster comparisons
- better generalization
- scalable to many identities

We compare **numbers**, not raw pixels.

---

## ğŸ–¥ System Requirements

- CPU only (no GPU needed)
- 2GB+ RAM recommended
- webcam
- Windows / Linux / macOS
- Python 3.8+

---

## ğŸ›  Troubleshooting

Camera not opening?
â†’ try another camera index

Poor accuracy?
â†’ collect more samples + evaluate threshold

Model missing?
â†’ verify file paths

Import errors?
â†’ reinstall dependencies

---

## ğŸ“ Learning Goals

This project helps you understand:

- face detection
- facial alignment
- feature embeddings
- similarity matching
- real-time tracking

It focuses on **understanding the pipeline**, not just calling an API.

---

## ğŸ“œ License

Educational and research use.